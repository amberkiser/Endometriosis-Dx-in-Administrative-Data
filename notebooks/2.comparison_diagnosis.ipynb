{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd93a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, roc_auc_score, recall_score, confusion_matrix, precision_score, accuracy_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829db4ab",
   "metadata": {},
   "source": [
    "# Compare EHR and ENDO diagnoses\n",
    "\n",
    "* Metrics include: kappa, sensitivity, specificity, AUC, PPV, NPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.read_pickle('../data/combined_data.pkl')\n",
    "\n",
    "# pos = dx with endo in EHR after study, neg = dx with endo in EHR prior to study\n",
    "combined['months_between'] = ((combined['EHR_Dx_Date'] - combined['ENDO_study_date']) / \n",
    "                              np.timedelta64(1, 'M')).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnosis_dataframe(original, threshold, cohort):\n",
    "    if threshold is None:\n",
    "        keep_dx = original.groupby(['Masked_PersonID','EndoID']).max().reset_index()\n",
    "    else: \n",
    "        keep_dx = original.copy()\n",
    "\n",
    "        keep_dx.loc[(keep_dx['months_between'] > threshold), 'endo_dx_EHR'] = 0 \n",
    "        keep_dx.loc[(keep_dx['months_between'] > threshold), 'SE_EHR'] = 0 \n",
    "        keep_dx.loc[(keep_dx['months_between'] > threshold), 'OE_EHR'] = 0 \n",
    "        keep_dx.loc[(keep_dx['months_between'] > threshold), 'DE_EHR'] = 0 \n",
    "        keep_dx.loc[(keep_dx['months_between'] > threshold), 'other_EHR'] = 0\n",
    "\n",
    "        keep_dx = keep_dx.groupby(['Masked_PersonID','EndoID']).max().reset_index()\n",
    "        \n",
    "    keep_dx = keep_dx.loc[keep_dx['Cohort_final'] == cohort]\n",
    "    return keep_dx\n",
    "\n",
    "def bootstrap_performance_metrics(prediction_data):\n",
    "    # Bootstrap the data\n",
    "    boot_data = resample(prediction_data, stratify=prediction_data['endo_dx_ENDO'])\n",
    "\n",
    "    # Performance metrics\n",
    "    acc = accuracy_score(boot_data['endo_dx_ENDO'], boot_data['endo_dx_EHR'])\n",
    "    auc = roc_auc_score(boot_data['endo_dx_ENDO'], boot_data['endo_dx_EHR'])\n",
    "    ppv = precision_score(boot_data['endo_dx_ENDO'], boot_data['endo_dx_EHR'])\n",
    "    sensitivity = recall_score(boot_data['endo_dx_ENDO'], boot_data['endo_dx_EHR'])\n",
    "    tn, fp, fn, tp = confusion_matrix(boot_data['endo_dx_ENDO'], boot_data['endo_dx_EHR']).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    npv = tn / (tn + fn)\n",
    "    kappa = cohen_kappa_score(boot_data['endo_dx_ENDO'], boot_data['endo_dx_EHR'])\n",
    "    \n",
    "    # Collect metrics in dataframe\n",
    "    bootstrap_df = pd.DataFrame({'AGREEMENT': [acc],\n",
    "                                 'AUC': [auc],\n",
    "                                 'PPV': [ppv],\n",
    "                                 'NPV': [npv],\n",
    "                                 'SENSITIVITY': [sensitivity],\n",
    "                                 'SPECIFICITY': [specificity],\n",
    "                                 'KAPPA': [kappa]})\n",
    "    return bootstrap_df\n",
    "\n",
    "def summarize_bootstrap_results(bootstrap_results):    \n",
    "    alpha = 100-95\n",
    "    metrics = []\n",
    "    medians = []\n",
    "    ci_low = []\n",
    "    ci_high = []\n",
    "    \n",
    "    for col in bootstrap_results.columns:\n",
    "        metrics.append(col)\n",
    "        medians.append(np.percentile(bootstrap_results[col], 50))\n",
    "        ci_low.append(np.percentile(bootstrap_results[col], alpha/2))\n",
    "        ci_high.append(np.percentile(bootstrap_results[col], 100-alpha/2))\n",
    "\n",
    "    metrics = pd.DataFrame({'METRIC': metrics, 'MEDIAN': medians, 'CI_LOW': ci_low, 'CI_HIGH': ci_high})\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038e971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EHR dx more than 1 month after study date are voided\n",
    "threshold = 1\n",
    "keep_dx = get_diagnosis_dataframe(combined, threshold, 1)\n",
    "bootstrap_results = pd.DataFrame()\n",
    "for i in range(n):\n",
    "    bootstrap_results = pd.concat([bootstrap_results, bootstrap_performance_metrics(keep_dx)])\n",
    "metrics = summarize_bootstrap_results(bootstrap_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272bcfb-161b-4b33-8f41-dba70eb5a39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbbeeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_csv('../results/diagnosis/metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137ce82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
